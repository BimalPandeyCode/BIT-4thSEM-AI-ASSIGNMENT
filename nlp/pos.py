# Word tokenization
import string
import nltk
nltk.download('averaged_perceptron_tagger')
tag_descriptions = {
    'CC': 'Coordinating conjunction',
    'CD': 'Cardinal number',
    'DT': 'Determiner',
    'EX': 'Existential there',
    'FW': 'Foreign word',
    'IN': 'Preposition or subordinating conjunction',
    'JJ': 'Adjective',
    'JJR': 'Adjective, comparative',
    'JJS': 'Adjective, superlative',
    'LS': 'List item marker',
    'MD': 'Modal',
    'NN': 'Noun, singular or mass',
    'NNS': 'Noun, plural',
    'NNP': 'Proper noun, singular',
    'NNPS': 'Proper noun, plural',
    'PDT': 'Predeterminer',
    'POS': 'Possessive ending',
    'PRP': 'Personal pronoun',
    'PRP$': 'Possessive pronoun',
    'RB': 'Adverb',
    'RBR': 'Adverb, comparative',
    'RBS': 'Adverb, superlative',
    'RP': 'Particle',
    'SYM': 'Symbol',
    'TO': 'to',
    'UH': 'Interjection',
    'VB': 'Verb, base form',
    'VBD': 'Verb, past tense',
    'VBG': 'Verb, gerund or present participle',
    'VBN': 'Verb, past participle',
    'VBP': 'Verb, non-3rd person singular present',
    'VBZ': 'Verb, 3rd person singular present',
    'WDT': 'Wh-determiner',
    'WP': 'Wh-pronoun',
    'WP$': 'Possessive wh-pronoun',
    'WRB': 'Wh-adverb',
    '.': 'Punctuation mark'
}

s = input("Enter your sentence: ")


def tokenize(str):

    words = str.split()
    print("Your POS words are: ")
    finalOutput = []
    for word in words:
        output = ""
        for letter in word:
            if (letter not in string.punctuation):
                output += letter
        finalOutput.append(output)
    return finalOutput


tokenizedString = tokenize(s)

tagged = nltk.pos_tag(tokenizedString)
tagged_words = [
    f"{word}--------{tag_descriptions.get(tag, tag)}" for word, tag in tagged]
formatted_text = '\n'.join(tagged_words)
print(formatted_text)
